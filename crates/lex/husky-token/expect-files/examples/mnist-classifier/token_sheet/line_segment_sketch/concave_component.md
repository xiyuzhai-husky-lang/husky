TokenSheetData {
    tokens: [
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `convexity`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Ident(
            `geom2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::TypeEntity(
                Struct,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::InlineCurl,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `LineSegmentSketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `CyclicSlice`,
        ),
        TokenData::Ident(
            `LineSegmentStroke`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::InlineCurl,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Impl,
        ),
        TokenData::Ident(
            `Visualize`,
        ),
        TokenData::Keyword(
            Keyword::Connection(
                For,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `visualize`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Visual`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `visualize`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Impl,
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Memo,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Memo,
            ),
        ),
        TokenData::Ident(
            `rel_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Closed(
                        BinaryClosedOpr::Div,
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Memo,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Float(
                Unspecified(
                    UnspecifiedFloatLiteral(
                        Id {
                            value: 109,
                        },
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `curve_start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `curve_ls`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `dp_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `curve_ls`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Comparison(
                        BinaryComparisonOpr::Leq,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `point_dist`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `curve_ls`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `dist_to_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                If,
            ),
        ),
        TokenData::Ident(
            `point_dist`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `point_dist`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `hausdorff_norm`,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Memo,
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Float(
                Unspecified(
                    UnspecifiedFloatLiteral(
                        Id {
                            value: 110,
                        },
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `dp0`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `dp`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::AssignClosed(
                        BinaryClosedOpr::Add,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `dp0`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `angle_to`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `dp`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Bool(
                True,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `dp0`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `dp`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Memo,
            ),
        ),
        TokenData::Ident(
            `bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `BoundingBox`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start_point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Comparison(
                        BinaryComparisonOpr::Leq,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `min`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `max`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `x`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `min`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `max`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `point`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `y`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `BoundingBox`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ClosedRange`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `xmin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `xmax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `ClosedRange`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ymin`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `ymax`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Memo,
            ),
        ),
        TokenData::Ident(
            `relative_bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `RelativeBoundingBox`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `relative_bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `bounding_box`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `LineSegment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `LineSegment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `last`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Point2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Point2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `last`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `clone`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Vector2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `line_segment`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `start_tangent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Vector2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `first`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `end_tangent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `Vector2d`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `last`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `displacement`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Fugitive(
                Fn,
            ),
        ),
        TokenData::Ident(
            `find_concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `LineSegmentSketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `ilen`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Integer(
                UnspecifiedRegular(
                    0,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Integer(
                UnspecifiedRegular(
                    1,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                While,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Minus,
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::WordOpr(
            WordOpr::And,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Ident(
            `is_convex`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Suffix(
                    Decr,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `ccv_start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                While,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `ccv_start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Closed(
                        BinaryClosedOpr::Add,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                While,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Comparison(
                        BinaryComparisonOpr::Leq,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Closed(
                        BinaryClosedOpr::Add,
                    ),
                ),
            ),
        ),
        TokenData::Ident(
            `L`,
        ),
        TokenData::WordOpr(
            WordOpr::And,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Exclamation,
            ),
        ),
        TokenData::Ident(
            `is_convex`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Suffix(
                    Incr,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                If,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RaOrGt,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Closed(
                        BinaryClosedOpr::Add,
                    ),
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Integer(
                UnspecifiedRegular(
                    1,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `push`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `line_segment_sketch`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `strokes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `cyclic_slice_leashed`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Bra(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Ket(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Ident(
            `end`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `start`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::Closed(
                        BinaryClosedOpr::Add,
                    ),
                ),
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Integer(
                UnspecifiedRegular(
                    1,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
    ],
    token_verses: TokenVerses {
        main_sequence: MainTokenVerseSequence {
            verses_data: [
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            1,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            7,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            15,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            23,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            29,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            33,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            49,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            54,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            61,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            68,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            71,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            76,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            79,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            84,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            97,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            102,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            107,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            120,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            128,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            140,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            159,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            170,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            179,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            184,
                        ),
                    ),
                    indent: 16,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            187,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            189,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            194,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            199,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            219,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            238,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            251,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            261,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            264,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            266,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            271,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            284,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            291,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            298,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            305,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            312,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            331,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            342,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            352,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            362,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            372,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            382,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            400,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            405,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            417,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            424,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            456,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            463,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            477,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            484,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            498,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            505,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            514,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            521,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            533,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            540,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            552,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            566,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            576,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            586,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            591,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            596,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            610,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            612,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            616,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            623,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            638,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            640,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            647,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            667,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            670,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            675,
                        ),
                    ),
                    indent: 4,
                },
            ],
        },
        nested_sequences: [],
    },
}