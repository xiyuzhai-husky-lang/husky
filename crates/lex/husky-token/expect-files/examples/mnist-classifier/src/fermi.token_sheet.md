```rust
TokenSheetData {
    tokens: [
        TokenData::Keyword(
            Keyword::Use,
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                Crate,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::ScopeResolution,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Star,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::TypeEntity(
                Struct,
            ),
        ),
        TokenData::Ident(
            `FermiMatchResult`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::InlineCurl,
                ),
            ),
        ),
        TokenData::Ident(
            `matches`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Question,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::InlineCurl,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Impl,
        ),
        TokenData::Ident(
            `FermiMatchResult`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Form(
                Memo,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Float(
                Unspecified(
                    UnspecifiedFloatLiteral(
                        Id {
                            value: 90,
                        },
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `ilen`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `max`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Keyword(
            Keyword::Form(
                Memo,
            ),
        ),
        TokenData::Ident(
            `rel_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Float(
                Unspecified(
                    UnspecifiedFloatLiteral(
                        Id {
                            value: 91,
                        },
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `ilen`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `max`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `rel_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Keyword(
            Keyword::Form(
                Memo,
            ),
        ),
        TokenData::Ident(
            `angle_change_norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Literal(
            LiteralTokenData::Float(
                Unspecified(
                    UnspecifiedFloatLiteral(
                        Id {
                            value: 92,
                        },
                    ),
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `ilen`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `max`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Pronoun(
                SelfValue,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `angle_change`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `abs`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `norm`,
        ),
        TokenData::Keyword(
            Keyword::Pub,
        ),
        TokenData::Keyword(
            Keyword::Form(
                Fn,
            ),
        ),
        TokenData::Ident(
            `fermi_match`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `templates`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Form(
                Fn,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Question,
            ),
        ),
        TokenData::Ident(
            `f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Binary(
                    SynBinaryOpr::CurryType,
                ),
            ),
        ),
        TokenData::Ident(
            `FermiMatchResult`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `concave_components`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `collect_leashes`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Keyword(
            Keyword::Modifier(
                Mut,
            ),
        ),
        TokenData::Ident(
            `matches`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Question,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Tilde,
            ),
        ),
        TokenData::Ident(
            `ConcaveComponent`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                NonImplFor,
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LaOrLt,
            ),
        ),
        TokenData::Ident(
            `templates`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `ilen`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Colon,
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Let,
            ),
        ),
        TokenData::Ident(
            `template`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Eq,
            ),
        ),
        TokenData::Ident(
            `templates`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `i`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Box,
                ),
            ),
        ),
        TokenData::Ident(
            `matches`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `push`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Dot,
            ),
        ),
        TokenData::Ident(
            `pop_with_largest_opt_f32`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `template`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Keyword(
            Keyword::Stmt(
                Return,
            ),
        ),
        TokenData::Ident(
            `FermiMatchResult`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::LeftDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
        TokenData::Ident(
            `matches`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::Comma,
            ),
        ),
        TokenData::Ident(
            `others`,
        ),
        TokenData::Punctuation(
            Punctuation(
                PunctuationMapped::RightDelimiter(
                    Delimiter::Par,
                ),
            ),
        ),
    ],
    token_verses: TokenVerses {
        main_sequence: MainTokenVerseSequence {
            verses_data: [
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            1,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            5,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            25,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            28,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            33,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            40,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            51,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            66,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            68,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            73,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            80,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            91,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            106,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            108,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            113,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            120,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            131,
                        ),
                    ),
                    indent: 12,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            150,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            152,
                        ),
                    ),
                    indent: 0,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            181,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            190,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            202,
                        ),
                    ),
                    indent: 4,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            211,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            218,
                        ),
                    ),
                    indent: 8,
                },
                TokenVerseData {
                    start: TokenVerseStart(
                        TokenIdx(
                            229,
                        ),
                    ),
                    indent: 4,
                },
            ],
        },
        nested_sequences: [],
    },
}
```